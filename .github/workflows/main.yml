name: Run M3U Scraper

on:
  workflow_dispatch:
  schedule:
    # Run every 16 minutes from 8:00 to 23:00 only
    - cron: "*/16 8-23 * * *"

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install dependencies
        run: |
          npm install puppeteer@latest puppeteer-extra puppeteer-extra-plugin-stealth

      - name: Create scraper script
        run: |
          cat << 'EOF' > scraper.js
          const puppeteer = require('puppeteer-extra');
          const StealthPlugin = require('puppeteer-extra-plugin-stealth');
          const fs = require('fs');

          puppeteer.use(StealthPlugin());

          const urls = [
            'https://www.gledaitv.fan/nova-live-tv.html',
            'https://www.gledaitv.fan/mtv-00s-live-tv.html',
            'https://www.gledaitv.fan/btv-live-tv.html',
            'https://iptv-bg.com/bnt-1-online/',
            'https://www.gledaitv.live/watch-tv/60/nova-tv-online'
          ];

          const delay = ms => new Promise(res => setTimeout(res, ms));

          (async () => {
            const browser = await puppeteer.launch({
              headless: true,
              args: ['--no-sandbox', '--disable-setuid-sandbox']
            });

            const results = [];

            for (const site of urls) {
              try {
                const page = await browser.newPage();

                // Set realistic user agent and viewport
                const customUA = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36';
                await page.setUserAgent(customUA);
                await page.setViewport({ width: 1280, height: 800 });

                let playlistLink = null;
                let playlistHeaders = null;

                // Catch .m3u8 requests
                page.on('request', request => {
                  const url = request.url();
                  if (url.match(/\.m3u8(\?.*)?$/i) && !playlistLink) {
                    playlistLink = url;
                    playlistHeaders = request.headers();
                  }
                });

                await page.goto(site, { waitUntil: 'networkidle2' });

                // Wait longer for Cloudflare verification: 15â€“25 sec
                await delay(15000 + Math.random() * 10000);

                // Optional: wait for page content to appear
                try {
                  await page.waitForSelector('body', { timeout: 30000 });
                } catch (err) {
                  console.warn(`Timeout waiting for page content on ${site}`);
                }

                // Fallback: scan HTML for .m3u8
                if (!playlistLink) {
                  const html = await page.content();
                  const regex = /https?:\/\/[^\s'"]+\.m3u8[^\s'"]*/gi;
                  const matches = html.match(regex);
                  if (matches && matches.length > 0) {
                    playlistLink = matches[0];
                    playlistHeaders = {
                      'referer': site,
                      'user-agent': customUA,
                      'origin': new URL(site).origin
                    };
                  }
                }

                await page.close();

                if (!playlistLink) {
                  console.error(`No playlist link found for ${site}`);
                  continue;
                }

                const formattedHeaders = [];
                if (playlistHeaders['referer']) formattedHeaders.push(`Referer: ${playlistHeaders['referer']}`);
                if (playlistHeaders['user-agent']) formattedHeaders.push(`User-Agent: ${playlistHeaders['user-agent']}`);
                if (playlistHeaders['origin']) formattedHeaders.push(`Origin: ${playlistHeaders['origin']}`);

                // Extract last segment of URL as title, removing .html if present
                const title = site.split('/').filter(Boolean).pop().replace(/\.html$/i, '');

                results.push({
                  title,
                  updated: new Date().toISOString(),
                  url: playlistLink,
                  headers: formattedHeaders.join('\n')
                });

              } catch (err) {
                console.error(`Error processing ${site}:`, err.message);
              }
            }

            await browser.close();

            fs.writeFileSync('channels.json', JSON.stringify(results, null, 2));
            console.log('All playlist links saved to channels.json:\n', results);
          })();
          EOF

      - name: Run scraper
        run: node scraper.js

      - name: Commit & Push JSON
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add channels.json
          git commit -m "Update channels list" || echo "No changes to commit"
          git push
